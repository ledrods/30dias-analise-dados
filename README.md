📅 Cronograma de 30 Dias - Estudo e Projetos de Análise de Dados
Este repositório contém um cronograma de estudo de 30 dias focado em análise de dados, ciência de dados e desenvolvimento de projetos práticos. O objetivo é construir um portfólio sólido e adquirir habilidades essenciais para se candidatar a vagas de estágio na área.

🎯 Objetivo Geral
Desenvolver dois projetos completos de análise de dados e machine learning.

Adquirir conhecimentos em SQL, Python, machine learning, APIs e cloud computing.

Preparar um portfólio técnico para vagas de estágio em análise de dados/ciência de dados.

📚 Cronograma Detalhado
🔹 Semana 1 – Fundamentos, Estatística e SQL
Dia 1-2: Revisão de Python (Pandas, NumPy) e SQL básico (SELECT, JOINs, GROUP BY).

Dia 3: Revisão de estatística básica (probabilidade, distribuições, testes de hipóteses).

Dia 4: Manipulação de dados (limpeza, transformação, agregações).

Dia 5: Consultas SQL avançadas + práticas com banco de dados real (PostgreSQL ou MySQL).

Dia 6-7: 🚀 Início do Projeto 1:

Escolha um dataset do Kaggle (ex: Vendas, RH, Finanças).

Faça análise exploratória e crie visualizações (Matplotlib, Seaborn, Plotly).

Documente os insights no GitHub.

🔹 Semana 2 – Machine Learning e Validação de Modelos
Dia 8-9: Modelos básicos: Regressão Linear, Árvores de Decisão.

Dia 10: Validação de modelos: Cross-validation, métricas (MSE, R², F1-score).

Dia 11: Modelos avançados: Random Forest, Gradient Boosting (XGBoost).

Dia 12-13: Otimização de modelos: GridSearchCV, Hyperparameter Tuning.

Dia 14: 🚀 Avanço no Projeto 1:

Treine um modelo preditivo (ex: prever vendas ou churn de clientes).

Documente o processo e os resultados no GitHub.

🔹 Semana 3 – Engenharia de Dados, APIs e Cloud
Dia 15-16: Manipulação de JSON, XML, CSV com Python.

Dia 17: Criando APIs com FastAPI para servir modelos de ML.

Dia 18: Docker: Conceitos básicos e containerização de aplicações.

Dia 19-20: Cloud Computing (AWS/GCP): Fundamentos de deploy de modelos.

Dia 21: 🚀 Início do Projeto 2:

Crie uma API para servir um modelo preditivo via FastAPI.

Teste a API localmente e documente no GitHub.

🔹 Semana 4 – IA Generativa, Otimização e Finalização dos Projetos
Dia 22-23: Introdução a LLMs e LangChain (básico sobre GenAI).

Dia 24-25: Modelos de ensembles (Stacking, Boosting, Bagging).

Dia 26: Deploy na nuvem (Render, AWS ou GCP).

Dia 27-28: 🚀 Finalização dos Projetos e ajustes:

Finalize o Projeto 1 e o Projeto 2.

Garanta que ambos estejam bem documentados no GitHub.

Dia 29-30: Preparação do portfólio + revisão de conceitos.

📂 Projetos no Portfólio
1️⃣ Projeto 1 – Análise Exploratória e Predição
Objetivo: Escolher um dataset real, fazer análise exploratória, criar visualizações e treinar um modelo preditivo.

Tecnologias: Python, Pandas, Matplotlib, Seaborn, Plotly, Scikit-learn.

Resultado: Modelo preditivo otimizado e insights documentados.

2️⃣ Projeto 2 – API para Machine Learning
Objetivo: Criar uma API com FastAPI para servir um modelo de machine learning.

Tecnologias: FastAPI, Docker, Cloud (AWS/GCP/Render).

Resultado: API funcional, com deploy local ou na nuvem.

🛠️ Ferramentas e Tecnologias Utilizadas
Linguagens: Python, SQL.

Bibliotecas: Pandas, NumPy, Matplotlib, Seaborn, Plotly, Scikit-learn, XGBoost, FastAPI.

Banco de Dados: PostgreSQL, MySQL.

Ferramentas de Deploy: Docker, AWS, GCP, Render.

Controle de Versão: GitHub.